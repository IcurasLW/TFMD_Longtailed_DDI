{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "features_path = './dataset/complete_drug_features.csv'\n",
    "ddis_path = './dataset/complete_ddis.csv'\n",
    "df_features = pd.read_csv(features_path)\n",
    "df_ddi = pd.read_csv(ddis_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>name1</th>\n",
       "      <th>id2</th>\n",
       "      <th>name2</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB06605</td>\n",
       "      <td>Apixaban</td>\n",
       "      <td>DB00001</td>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>Drug A may increase the anticoagulant activiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB06695</td>\n",
       "      <td>Dabigatran etexilate</td>\n",
       "      <td>DB00001</td>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>Drug A may increase the anticoagulant activiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB01254</td>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>DB00001</td>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>The risk or severity of bleeding and hemorrhag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB00001</td>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>DB01609</td>\n",
       "      <td>Deferasirox</td>\n",
       "      <td>The risk or severity of gastrointestinal bleed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00001</td>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>DB01586</td>\n",
       "      <td>Ursodeoxycholic acid</td>\n",
       "      <td>The risk or severity of bleeding and bruising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515083</th>\n",
       "      <td>DB17088</td>\n",
       "      <td>Famtozinameran</td>\n",
       "      <td>DB14845</td>\n",
       "      <td>Filgotinib</td>\n",
       "      <td>The therapeutic efficacy of Drug A can be decr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515084</th>\n",
       "      <td>DB17088</td>\n",
       "      <td>Famtozinameran</td>\n",
       "      <td>DB15091</td>\n",
       "      <td>Upadacitinib</td>\n",
       "      <td>The therapeutic efficacy of Drug A can be decr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515085</th>\n",
       "      <td>DB17088</td>\n",
       "      <td>Famtozinameran</td>\n",
       "      <td>DB16650</td>\n",
       "      <td>Deucravacitinib</td>\n",
       "      <td>The therapeutic efficacy of Drug A can be decr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515086</th>\n",
       "      <td>DB17088</td>\n",
       "      <td>Famtozinameran</td>\n",
       "      <td>DB16703</td>\n",
       "      <td>Belumosudil</td>\n",
       "      <td>The therapeutic efficacy of Drug A can be decr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515087</th>\n",
       "      <td>DB00277</td>\n",
       "      <td>Theophylline</td>\n",
       "      <td>DB17088</td>\n",
       "      <td>Famtozinameran</td>\n",
       "      <td>The serum concentration of Drug A can be incre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515088 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id1                 name1      id2                 name2   \n",
       "0       DB06605              Apixaban  DB00001             Lepirudin  \\\n",
       "1       DB06695  Dabigatran etexilate  DB00001             Lepirudin   \n",
       "2       DB01254             Dasatinib  DB00001             Lepirudin   \n",
       "3       DB00001             Lepirudin  DB01609           Deferasirox   \n",
       "4       DB00001             Lepirudin  DB01586  Ursodeoxycholic acid   \n",
       "...         ...                   ...      ...                   ...   \n",
       "515083  DB17088        Famtozinameran  DB14845            Filgotinib   \n",
       "515084  DB17088        Famtozinameran  DB15091          Upadacitinib   \n",
       "515085  DB17088        Famtozinameran  DB16650       Deucravacitinib   \n",
       "515086  DB17088        Famtozinameran  DB16703           Belumosudil   \n",
       "515087  DB00277          Theophylline  DB17088        Famtozinameran   \n",
       "\n",
       "                                              interaction  \n",
       "0       Drug A may increase the anticoagulant activiti...  \n",
       "1       Drug A may increase the anticoagulant activiti...  \n",
       "2       The risk or severity of bleeding and hemorrhag...  \n",
       "3       The risk or severity of gastrointestinal bleed...  \n",
       "4       The risk or severity of bleeding and bruising ...  \n",
       "...                                                   ...  \n",
       "515083  The therapeutic efficacy of Drug A can be decr...  \n",
       "515084  The therapeutic efficacy of Drug A can be decr...  \n",
       "515085  The therapeutic efficacy of Drug A can be decr...  \n",
       "515086  The therapeutic efficacy of Drug A can be decr...  \n",
       "515087  The serum concentration of Drug A can be incre...  \n",
       "\n",
       "[515088 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ddi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SMILES.txt', 'w') as f:\n",
    "     f.write('\\n'.join(str(x) for x in df_features['Smiles']))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/homes/Nathan/Implementation'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "script_folder = os.getcwd()\n",
    "script_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "vocab_path = os.getcwd() +\"/Embeddings/bart_vocab.txt\"\n",
    "text = Path(vocab_path).read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from pathlib import Path\n",
    "\n",
    "import molbart.util as util\n",
    "from molbart.decoder import DecodeSampler\n",
    "from molbart.models.pre_train import BARTModel\n",
    "from molbart.data.datasets import ReactionDataset\n",
    "from molbart.data.datamodules import FineTuneReactionDataModule\n",
    "import os\n",
    "\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 20\n",
    "DEFAULT_NUM_BEAMS = 10\n",
    "\n",
    "\n",
    "class SmilesError(Exception):\n",
    "    def __init__(self, idx, smi):\n",
    "        message = f\"RDKit could not parse smiles {smi} at index {idx}\"\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "def build_dataset(args):\n",
    "    text = Path(args.reactants_path).read_text()\n",
    "    smiles = text.split(\"\\n\")\n",
    "    smiles = [smi for smi in smiles if smi != \"\" and smi is not None]\n",
    "    dataset = ReactionDataset(smiles, smiles)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def build_datamodule(args, dataset, tokeniser, max_seq_len):\n",
    "    test_idxs = range(len(dataset))\n",
    "    dm = FineTuneReactionDataModule(\n",
    "        dataset,\n",
    "        tokeniser,\n",
    "        args.batch_size,\n",
    "        max_seq_len,\n",
    "        val_idxs=[],\n",
    "        test_idxs=test_idxs\n",
    "    )\n",
    "    return dm\n",
    "\n",
    "\n",
    "def concat_tensor(tensor_1, tensor_2):\n",
    "    pass\n",
    "\n",
    "def smiles_embedding(model, smiles_loader):\n",
    "    device = \"cuda:0\" if util.use_gpu else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for _, batch in enumerate(smiles_loader):\n",
    "        device_batch = {\n",
    "            key: val.to(device) if type(val) == torch.Tensor else val for key, val in batch.items()\n",
    "        }\n",
    "\n",
    "        enc_input = device_batch[\"encoder_input\"]\n",
    "        enc_mask = device_batch[\"encoder_pad_mask\"]\n",
    "\n",
    "        # Freezing the weights reduces the amount of memory leakage in the transformer\n",
    "        model.freeze()\n",
    "\n",
    "        encode_input = {\n",
    "            \"encoder_input\": enc_input,\n",
    "            \"encoder_pad_mask\": enc_mask\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            embedding = model.encode(encode_input)\n",
    "            memory = model.encoder(embedding)\n",
    "            print(memory)\n",
    "            # 把tensor接上\n",
    "    model.unfreeze()\n",
    "    return memory\n",
    "\n",
    "\n",
    "def encode_smiles(args):\n",
    "    print(\"Building tokeniser...\")\n",
    "    tokeniser = util.load_tokeniser(args.vocab_path, args.chem_token_start_idx)\n",
    "    print(\"Finished tokeniser...\")\n",
    "\n",
    "    print(\"Reading SMILES...\")\n",
    "    dataset = build_dataset(args)\n",
    "    print(\"Finished SMILES...\")\n",
    "\n",
    "    sampler = DecodeSampler(tokeniser, util.DEFAULT_MAX_SEQ_LEN)\n",
    "\n",
    "    print(\"Loading model...\")\n",
    "    model = util.load_bart(args, sampler)\n",
    "    model.num_beams = args.num_beams\n",
    "    sampler.max_seq_len = model.max_seq_len\n",
    "    print(\"Finished model...\")\n",
    "\n",
    "    print(\"Building data loader...\")\n",
    "    dm = build_datamodule(args, dataset, tokeniser, model.max_seq_len)\n",
    "    dm.setup()\n",
    "    test_loader = dm.test_dataloader()\n",
    "    print(\"Finished loader...\")\n",
    "\n",
    "    print(\"Embedding SMILES...\")\n",
    "    embeddings = smiles_embedding(model, test_loader)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    working_dir = os.getcwd()\n",
    "    smile_path = '/Embeddings/SMILES_1.txt'\n",
    "    model_path = \"/Embeddings/models/pre-trained/combined-large/step=1000000.ckpt\"\n",
    "    vocab_path = \"/Embeddings/bart_vocab.txt\"\n",
    "    # Program level args\n",
    "    parser.add_argument(\"--reactants_path\", type=str, default=working_dir + smile_path)  # Each line is a input SMILES\n",
    "    parser.add_argument(\"--model_path\", type=str, default=working_dir + model_path)\n",
    "    parser.add_argument(\"--products_path\", type=str, default=\"embedding.pickle\")\n",
    "    parser.add_argument(\"--vocab_path\", type=str, default=working_dir + vocab_path)\n",
    "    parser.add_argument(\"--chem_token_start_idx\", type=int, default=util.DEFAULT_CHEM_TOKEN_START)\n",
    "\n",
    "    # Model args\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=DEFAULT_BATCH_SIZE)\n",
    "    parser.add_argument(\"--num_beams\", type=int, default=DEFAULT_NUM_BEAMS)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    embed = encode_smiles(args)\n",
    "    print(embed.size())\n",
    "    print('--------------')\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "590c26b7f2937bfcecb0a5796d3a0066be0ce7e9830b13c53de43dd49be9b17a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
